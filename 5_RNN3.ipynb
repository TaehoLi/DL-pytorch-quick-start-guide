{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 3328586\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb\n",
    "\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file = unidecode.unidecode(open('data/warandpeace.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", as he jolted on his \n",
      "horse with a convoy officer's saddle. \n",
      "\n",
      "\"He wants to see a battle,\" said Zherk6v to \n",
      "Bolk6nski, pointing to the accountant, \"but \n",
      "he feels a pain in the pit of his stomach al- \n",
      "r\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10],\n",
      "        [11],\n",
      "        [12],\n",
      "        [39],\n",
      "        [40],\n",
      "        [41]])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long().unsqueeze(1)\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 50s (100 33%) 2.3101]\n",
      "Le \n",
      "cas the \n",
      "him \n",
      "ome dand He whis maid thet sed the comed \n",
      "is Ping was \n",
      "ind ne forsalt hate de \n",
      "the couly anded Wono- \n",
      "\n",
      "\n",
      "himy \n",
      "the whis \n",
      "whe- \n",
      "ate tor \n",
      "the hith butted she sere fount \n",
      "bznol an \n",
      "ned, anily and amifinof but inces ine? Theat, Oand desa the de awh ins ceute sos he whos ins hauted hat fous haraid \n",
      "inccorsed, inch \n",
      "\n",
      "if \n",
      "gaidis \n",
      "\n",
      "ipand SNillat ead \n",
      "lelang enis on \n",
      "her bunsin coudek him the liliclawawth aned af thouved ded \n",
      "eched edey ^hed huse so the I byke ched he and the wher sbes \n",
      "\n",
      "t \n",
      "\n",
      "[1m 57s (200 66%) 2.1545]\n",
      "Lexkne mout the non elpstord in is tere to bednow our a ince prut and \n",
      "\n",
      "\n",
      "Ony and \n",
      "tho- \n",
      "to cormes, novinove mere \n",
      "in an aly arded \n",
      "to nor and \n",
      "restors he amared in whorout mos. \n",
      "\n",
      "\n",
      "\n",
      "\"haid he expat. I \n",
      "the pomorise deming \n",
      "ther \n",
      "balk \n",
      "but that repill \n",
      "amponge. \n",
      "\n",
      "\n",
      "Nithill at rnurosmaid and \n",
      "pew but \n",
      "the not oruterer had Poid \n",
      "nowness sithing aspbuss whis \n",
      "tuped \n",
      "sat the piarn and whould so the ressknor an \n",
      "the bey, \n",
      "\n",
      "lovs and feser \n",
      "\n",
      "butating of of the \n",
      "thever \n",
      "to Naron as the Fonge corom. Bulfor \n",
      "to \n",
      "\n",
      "[3m 2s (300 100%) 2.1166]\n",
      "Lexe. hust in conmable didsed, Fruncame the peresich, \n",
      "fard, and as cormthad whera greating the resprecover the his sofrown the \n",
      "ruce \n",
      "gherthers the gured genlled who fracters Burthigne and soff the roke of the frem, conce some sren comcertrion,\" maider, and inder's is oren whole bat the Pronsers, a okeng loid in on- \n",
      "Naped \n",
      "the in from pressent?\" Vos gener out the on hew, it troch, uriever the not oniing reenor diech, anfir ther his dictht rechen crame what have trid \n",
      "the laing \n",
      "the reand and \n",
      "fl \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#n_epochs = 2000\n",
    "n_epochs = 300\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = [0]\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    #loss = train(*random_training_set())  \n",
    "    loss = train(*random_training_set())\n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate('Le', 500), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
