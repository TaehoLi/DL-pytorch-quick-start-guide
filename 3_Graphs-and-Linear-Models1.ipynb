{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "\n",
    "class LogisticModel(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(LogisticModel, self).__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = torch.sigmoid(self.linear(x))\n",
    "        return out\n",
    "in_dim, out_dim =1,1    \n",
    "model = LogisticModel(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "optimiser =  torch.optim.SGD(model.parameters(), lr =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = torch.tensor([[1.6],[2.1],[1.3],[4.8],[3.5]], dtype=torch.float).reshape(-1,1)\n",
    "y_train = torch.tensor([[0],[0],[0],[1],[1]], dtype=torch.float).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, loss 1.0728323459625244\n",
      "epoch1, loss 1.0565154552459717\n",
      "epoch2, loss 1.0405337810516357\n",
      "epoch3, loss 1.0248911380767822\n",
      "epoch4, loss 1.009590744972229\n",
      "epoch5, loss 0.9946357607841492\n",
      "epoch6, loss 0.9800291061401367\n",
      "epoch7, loss 0.965772807598114\n",
      "epoch8, loss 0.9518685340881348\n",
      "epoch9, loss 0.938317596912384\n",
      "epoch10, loss 0.9251207113265991\n",
      "epoch11, loss 0.9122779965400696\n",
      "epoch12, loss 0.899789035320282\n",
      "epoch13, loss 0.8876531720161438\n",
      "epoch14, loss 0.8758689761161804\n",
      "epoch15, loss 0.8644344210624695\n",
      "epoch16, loss 0.8533471822738647\n",
      "epoch17, loss 0.8426042795181274\n",
      "epoch18, loss 0.832202136516571\n",
      "epoch19, loss 0.8221370577812195\n",
      "epoch20, loss 0.8124043345451355\n",
      "epoch21, loss 0.8029993772506714\n",
      "epoch22, loss 0.7939168214797974\n",
      "epoch23, loss 0.7851510047912598\n",
      "epoch24, loss 0.776695966720581\n",
      "epoch25, loss 0.7685453295707703\n",
      "epoch26, loss 0.7606927156448364\n",
      "epoch27, loss 0.7531309723854065\n",
      "epoch28, loss 0.7458532452583313\n",
      "epoch29, loss 0.7388520240783691\n",
      "epoch30, loss 0.7321200370788574\n",
      "epoch31, loss 0.7256497144699097\n",
      "epoch32, loss 0.7194334864616394\n",
      "epoch33, loss 0.7134634256362915\n",
      "epoch34, loss 0.7077319025993347\n",
      "epoch35, loss 0.7022312879562378\n",
      "epoch36, loss 0.6969536542892456\n",
      "epoch37, loss 0.6918915510177612\n",
      "epoch38, loss 0.6870371699333191\n",
      "epoch39, loss 0.6823831796646118\n",
      "epoch40, loss 0.6779219508171082\n",
      "epoch41, loss 0.6736462712287903\n",
      "epoch42, loss 0.6695491075515747\n",
      "epoch43, loss 0.6656234264373779\n",
      "epoch44, loss 0.6618622541427612\n",
      "epoch45, loss 0.6582590341567993\n",
      "epoch46, loss 0.6548072099685669\n",
      "epoch47, loss 0.6515005826950073\n",
      "epoch48, loss 0.6483327746391296\n",
      "epoch49, loss 0.645298182964325\n",
      "epoch50, loss 0.642390787601471\n",
      "epoch51, loss 0.6396051645278931\n",
      "epoch52, loss 0.6369360685348511\n",
      "epoch53, loss 0.6343781352043152\n",
      "epoch54, loss 0.6319263577461243\n",
      "epoch55, loss 0.6295760869979858\n",
      "epoch56, loss 0.6273226737976074\n",
      "epoch57, loss 0.62516188621521\n",
      "epoch58, loss 0.6230891942977905\n",
      "epoch59, loss 0.621100664138794\n",
      "epoch60, loss 0.619192361831665\n",
      "epoch61, loss 0.6173605918884277\n",
      "epoch62, loss 0.6156017184257507\n",
      "epoch63, loss 0.6139125823974609\n",
      "epoch64, loss 0.612289547920227\n",
      "epoch65, loss 0.6107298135757446\n",
      "epoch66, loss 0.6092301607131958\n",
      "epoch67, loss 0.6077878475189209\n",
      "epoch68, loss 0.606400191783905\n",
      "epoch69, loss 0.6050645112991333\n",
      "epoch70, loss 0.6037784218788147\n",
      "epoch71, loss 0.6025395393371582\n",
      "epoch72, loss 0.6013456583023071\n",
      "epoch73, loss 0.6001945734024048\n",
      "epoch74, loss 0.599084198474884\n",
      "epoch75, loss 0.5980127453804016\n",
      "epoch76, loss 0.5969782471656799\n",
      "epoch77, loss 0.5959789752960205\n",
      "epoch78, loss 0.5950132608413696\n",
      "epoch79, loss 0.5940794944763184\n",
      "epoch80, loss 0.5931761860847473\n",
      "epoch81, loss 0.5923018455505371\n",
      "epoch82, loss 0.5914551019668579\n",
      "epoch83, loss 0.5906346440315247\n",
      "epoch84, loss 0.5898392796516418\n",
      "epoch85, loss 0.5890676975250244\n",
      "epoch86, loss 0.588318943977356\n",
      "epoch87, loss 0.587591826915741\n",
      "epoch88, loss 0.5868853330612183\n",
      "epoch89, loss 0.5861985683441162\n",
      "epoch90, loss 0.5855304598808289\n",
      "epoch91, loss 0.5848802328109741\n",
      "epoch92, loss 0.5842471122741699\n",
      "epoch93, loss 0.5836300849914551\n",
      "epoch94, loss 0.5830286741256714\n",
      "epoch95, loss 0.5824418663978577\n",
      "epoch96, loss 0.5818692445755005\n",
      "epoch97, loss 0.5813099145889282\n",
      "epoch98, loss 0.5807634592056274\n",
      "epoch99, loss 0.5802291631698608\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    inputs, labels = x_train, y_train   \n",
    "    out = model(inputs)    \n",
    "    optimiser.zero_grad()    \n",
    "    loss = criterion(out, labels)    \n",
    "    loss.backward()    \n",
    "    optimiser.step()\n",
    "    predicted = model.forward(x_train)    \n",
    "    print('epoch{}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[0.2196]])), ('linear.bias', tensor([-0.5177]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3785], grad_fn=<SelectBackward>) false\n",
      "tensor([0.4531], grad_fn=<SelectBackward>) false\n",
      "tensor([0.4968], grad_fn=<SelectBackward>) false\n",
      "tensor([0.5352], grad_fn=<SelectBackward>) true\n",
      "tensor([0.7084], grad_fn=<SelectBackward>) true\n"
     ]
    }
   ],
   "source": [
    "test=torch.tensor([[0.1],[1.5],[2.3],[3.0],[6.4]])\n",
    "results = model(test)\n",
    "for result in results:\n",
    "    if result <= 0.5:\n",
    "        print(result,'false')\n",
    "    else: print(result, 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
